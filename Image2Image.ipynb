{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "import math\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, \n",
    "    padding=padding)\n",
    "def conv_n(in_channels, out_channels, kernel_size,stride=1,padding=0,inst_norm= False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels,out_channels, kernel_size, \n",
    "        stride=stride, padding=padding) , nn.InstanceNorm2d(out_channels,momentum=0.1,eps= 1e-5))\n",
    "    else :\n",
    "        return  nn.Sequential(nn.Conv2d(in_channels,out_channels, kernel_size, \n",
    "        stride=stride, padding=padding) , nn.BatchNorm2d(out_channels,momentum=0.1,eps= 1e-5))\n",
    "\n",
    "\n",
    "def tconv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0,):\n",
    "    return nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, \n",
    "    padding=padding, output_padding=output_padding)\n",
    "\n",
    "\n",
    "\n",
    "def tconv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, \n",
    "        stride=stride, padding=padding, output_padding=output_padding), \n",
    "        nn.InstanceNorm2d(out_channels, momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, \n",
    "        stride=stride, padding=padding, output_padding=output_padding), \n",
    "        nn.BatchNorm2d(out_channels, momentum=0.1, eps=1e-5),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_c = 3\n",
    "dim_g = 64\n",
    "\n",
    "# Generator\n",
    "class Gen(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Gen,self).__init__()\n",
    "        self.n1 = conv(dim_c, dim_g, 4, 2, 1) \n",
    "        self.n2 = conv_n(dim_g, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n3 = conv_n(dim_g*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n4 = conv_n(dim_g*4, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n5 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n6 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n7 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n8 = conv(dim_g*8, dim_g*8, 4, 2, 1)\n",
    "\n",
    "        self.m1 = tconv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m2 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m3 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m4 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m5 = tconv_n(dim_g*8*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m6 = tconv_n(dim_g*4*2, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m7 = tconv_n(dim_g*2*2, dim_g*1, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m8 = tconv(dim_g*1*2, dim_c, 4, 2, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        n1 = self.n1(x)\n",
    "        n2 = self.n2(F.leaky_relu(n1, 0.2))\n",
    "        n3 = self.n3(F.leaky_relu(n2, 0.2))\n",
    "        n4 = self.n4(F.leaky_relu(n3, 0.2))\n",
    "        n5 = self.n5(F.leaky_relu(n4, 0.2))\n",
    "        n6 = self.n6(F.leaky_relu(n5, 0.2))\n",
    "        n7 = self.n7(F.leaky_relu(n6, 0.2))\n",
    "        n8 = self.n8(F.leaky_relu(n7, 0.2))\n",
    "        m1 = torch.cat([F.dropout(self.m1(F.relu(n8)), 0.5, training=True), n7], 1)\n",
    "        m2 = torch.cat([F.dropout(self.m2(F.relu(m1)), 0.5, training=True), n6], 1)\n",
    "        m3 = torch.cat([F.dropout(self.m3(F.relu(m2)), 0.5, training=True), n5], 1)\n",
    "        m4 = torch.cat([self.m4(F.relu(m3)), n4], 1)\n",
    "        m5 = torch.cat([self.m5(F.relu(m4)), n3], 1)\n",
    "        m6 = torch.cat([self.m6(F.relu(m5)), n2], 1)\n",
    "        m7 = torch.cat([self.m7(F.relu(m6)), n1], 1)\n",
    "        m8 = self.m8(F.relu(m7))\n",
    "\n",
    "        return self.tanh(m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator = Gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_d = 64\n",
    "\n",
    "# Discriminator\n",
    "class Disc(nn.Module):\n",
    "    def __init__(self, inst_norm=False): \n",
    "        super(Disc,self).__init__()\n",
    "        self.c1 = conv(dim_c*2, dim_d, 4, 2, 1) \n",
    "        self.c2 = conv_n(dim_d, dim_d*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c3 = conv_n(dim_d*2, dim_d*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c4 = conv_n(dim_d*4, dim_d*8, 4, 1, 1, inst_norm=inst_norm)\n",
    "        self.c5 = conv(dim_d*8, 1, 4, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        xy=torch.cat([x,y],dim=1)\n",
    "        xy=F.leaky_relu(self.c1(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c2(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c3(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c4(xy), 0.2)\n",
    "        xy=self.c5(xy)\n",
    "\n",
    "        return self.sigmoid(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator = Disc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read = plt.imread('AllHumans/glued_human_face_101.jpg')\n",
    "\n",
    "# plt.imshow(read)\n",
    "\n",
    "# def Draw_images(images):\n",
    "#     for i in range(len(images)):\n",
    "#         read = plt.imread('AllHumans/'+images[i])\n",
    "#         plt.imshow(read)\n",
    "#         plt.show()\n",
    "\n",
    "# img = [i for i in os.walk('AllHumans/')][0][2]\n",
    "\n",
    "# Draw_images(img[:10])\n",
    "\n",
    "# read.shape\n",
    "\n",
    "# read.shape\n",
    "\n",
    "# plt.imshow(read[:,:256,:])\n",
    "\n",
    "# plt.imshow(read[:,256:,:])\n",
    "\n",
    "# training_images= [i for i in os.walk('AllHumans/')][0][2]\n",
    "\n",
    "# len(training_images)\n",
    "\n",
    "# 512//2\n",
    "\n",
    "# training_images = sorted(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(plt.imread('AllHumans/'+training_images[-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images,path):\n",
    "    original_images= {}\n",
    "    sketch_images = {}\n",
    "    for i in images:\n",
    "        read_images = plt.imread(path+i)\n",
    "        h,w,c = read_images.shape\n",
    "        original_images[i] =read_images[:,:w//2,:]\n",
    "        sketch_images[i] = read_images[:,w//2:,:]\n",
    "    return original_images , sketch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_image= [i for i in os.walk('test/')][0][2]\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # for i in list(ground_truth.keys()):\n",
    "# #     cv2.imwrite('ground_truth/'+i,ground_truth[i])\n",
    "    \n",
    "\n",
    "# # for i in list(sketch_images.keys()):\n",
    "# #     cv2.imwrite('sketch_images/'+i,sketch_images[i])\n",
    "\n",
    "# training_images= [i for i in os.walk('AllHumans/')][0][2]\n",
    "\n",
    "\n",
    "\n",
    "# sketch_images_df = pd.DataFrame(sorted([i for i in os.walk('sketch_images/')][0][2]),columns=['sketch_images_path'])\n",
    "\n",
    "# ground_truth_df = pd.DataFrame(sorted([i for i in os.walk('ground_truth/')][0][2]),columns=['ground_truth_path'])\n",
    "\n",
    "# training_data = pd.concat([sketch_images_df,ground_truth_df],axis=1)\n",
    "\n",
    "# training_data\n",
    "\n",
    "# ground_truth , sketch_images = preprocess_images(testing_image,'test/')\n",
    "\n",
    "# import cv2\n",
    "\n",
    "# # for i in list(ground_truth.keys()):\n",
    "# #     cv2.imwrite('ground_truth_test/'+i,ground_truth[i])\n",
    "\n",
    "# # for i in list(sketch_images.keys()):\n",
    "# #     cv2.imwrite('sketch_images_test/'+i,sketch_images[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sketch_images_test_df = pd.DataFrame(sorted([i for i in os.walk('sketch_images_test/')][0][2]),columns=['sketch_images'])\n",
    "\n",
    "# ground_truth_test_df = pd.DataFrame(sorted([i for i in os.walk('ground_truth_test/')][0][2]),columns=['ground_truth'])\n",
    "\n",
    "# sketch_images_test_df['sketch_images_path'] = sketch_images_test_df.sketch_images.apply(lambda x: 'sketch_images_test/'+x)\n",
    "# ground_truth_test_df['ground_truth_path'] = ground_truth_test_df.ground_truth.apply(lambda x: 'ground_truth_test/'+x)\n",
    "\n",
    "# ground_truth_test_df\n",
    "\n",
    "# validation_data = pd.concat([sketch_images_test_df,ground_truth_test_df],axis=1)\n",
    "\n",
    "# validation_data=validation_data.drop(columns=['sketch_images','ground_truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_data.to('validation_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(ground_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     plt.imshow(ground_truth[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     plt.imshow(sketch_images[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(plt.imread(sketch_images_df.iloc[2].image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(plt.imread(ground_truth_df.iloc[2].image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE = nn.BCELoss() #binary cross-entropy\n",
    "L1 = nn.L1Loss() \n",
    "\n",
    "#instance normalization\n",
    "Gen = Gen().cuda(0)\n",
    "Disc = Disc().cuda(0)\n",
    "\n",
    "#optimizers\n",
    "Gen_optim = torch.optim.Adam(Gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "Disc_optim = torch.optim.Adam(Disc.parameters(), lr=2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data.sketch_images_path = training_data.sketch_images_path.apply(lambda x: 'sketch_images/'+x)\n",
    "# training_data.ground_truth_path = training_data.ground_truth_path.apply(lambda x: 'ground_truth/'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "class dataset(Dataset): \n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data= data.copy()\n",
    "        self.transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)),])\n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        current = self.data.iloc[idx]\n",
    "        input_image = current['sketch_images_path']\n",
    "        target_image = current['ground_truth_path']\n",
    "        X = Image.open(input_image)\n",
    "        y = Image.open(target_image)\n",
    "        return self.transform(X) , self.transform(y)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "validation_data = pd.read_csv('validation_data.pkl')\n",
    "training_data = pd.read_pickle('training_data.pkl')\n",
    "\n",
    "validation_loader =  DataLoader(dataset(validation_data),5,shuffle=True)\n",
    "\n",
    "training_loader =  DataLoader(dataset(training_data),5,shuffle=True)\n",
    "x_test ,y_test = next(iter(validation_loader))\n",
    "x_train ,y_train = next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_E2S(batch1, batch2, title1, title2):\n",
    "    # edges\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title1)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch1, nrow=1, padding=5, \n",
    "    normalize=True).cpu(),(1,2,0)))\n",
    "    # faces\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title2)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch2, nrow=1, padding=5, \n",
    "    normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "show_E2S(y_train,x_train,\"input X (edges)\",\"ground truth y (faces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_batches(batch1, batch2, title1, title2, batch3, title3):\n",
    "    # batch1\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title1)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch1, nrow=1, padding=5, \n",
    "    normalize=True).cpu(), (1,2,0)))\n",
    "    # batch2\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title2)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch2, nrow=1, padding=5, \n",
    "    normalize=True).cpu(), (1,2,0)))\n",
    "    # third batch\n",
    "    \n",
    "#     if batch3:\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title3)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch3, nrow=1, padding=5, \n",
    "    normalize=True).cpu(), (1,2,0)))\n",
    "with torch.no_grad():\n",
    "    fk = Gen(x_test.cuda(0))\n",
    "compare_batches(x_test, fk, \"input image\", \"prediction\", y_test, \"ground truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "Disc_losses = Gen_losses = Gen_GAN_losses = Gen_L1_losses = []\n",
    "from tqdm import tqdm \n",
    "iter_per_plot = 500\n",
    "epochs = 10\n",
    "L1_lambda = 100.0\n",
    "\n",
    "Gen.train()\n",
    "for ep in range(epochs):\n",
    "    for steps, (x,y ) in tqdm(enumerate(training_loader)):\n",
    "        x = x.cuda(0)\n",
    "        y = y.cuda(0)\n",
    "        r_masks = torch.ones(x.size()[0],1,30,30).cuda(0) ## Real Mask\n",
    "        f_masks = torch.zeros(x.size()[0],1,30,30).cuda(0) ### Fask Mask \n",
    "\n",
    "        ############### why we use r_mask (5,1,30,30,)\n",
    "        #### because the output come from Disc are 30,30,\n",
    "        ### use that patch to calcuate loss and update the weight\n",
    "        # disc\n",
    "        Disc.zero_grad()\n",
    "        #real_patch\n",
    "        r_patch=Disc(y,x)\n",
    "        r_gan_loss=BCE(r_patch,r_masks)\n",
    "\n",
    "        fake=Gen(x)\n",
    "        #fake_patch\n",
    "        \n",
    "        f_patch = Disc(fake.detach(),x)\n",
    "        f_gan_loss=BCE(f_patch,f_masks)\n",
    "\n",
    "        Disc_loss =  f_gan_loss\n",
    "        Disc_loss.backward()\n",
    "        Disc_optim.step()\n",
    "\n",
    "        # gen\n",
    "        Gen.zero_grad()\n",
    "        f_patch = Disc(fake,x)\n",
    "        f_gan_loss=BCE(f_patch,r_masks)\n",
    "\n",
    "        L1_loss = L1(fake,y)\n",
    "        Gen_loss = f_gan_loss + L1_lambda*L1_loss\n",
    "        Gen_loss.backward()\n",
    "    \n",
    "        Gen_optim.step()\n",
    "        if (steps+1)%iter_per_plot == 0 :\n",
    "            print('Epoch [{}/{}], Step [{}/{}], disc_loss: {:.4f}, gen_loss: {:.4f},Disc(real): {:.2f}, Disc(fake):{:.2f}, gen_loss_gan:{:.4f}, gen_loss_L1:{:.4f}'.format(ep, epochs, steps+1, len(training_loader), Disc_loss.item(), Gen_loss.item(), r_patch.mean(), f_patch.mean(), f_gan_loss.item(), L1_loss.item()))\n",
    "            \n",
    "            Gen_losses.append(Gen_loss.item())\n",
    "            Disc_losses.append(Disc_loss.item())\n",
    "            Gen_GAN_losses.append(f_gan_loss.item())\n",
    "            Gen_L1_losses.append(L1_loss.item())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                Gen.eval()\n",
    "                for steps , (x_test, y_test) in tqdm(enumerate(validation_loader)):\n",
    "                    fake = Gen(x_test.cuda(0)).detach().cpu()\n",
    "                    \n",
    "                \n",
    "            figs=plt.figure(figsize=(10,10))\n",
    "\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"input image\")\n",
    "            plt.imshow(np.transpose(vutils.make_grid(x_test, nrow=1, padding=5, \n",
    "            normalize=True).cpu(), (1,2,0)))\n",
    "\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"generated image\")\n",
    "            plt.imshow(np.transpose(vutils.make_grid(fake, nrow=1, padding=5, \n",
    "            normalize=True).cpu(), (1,2,0)))\n",
    "      \n",
    "            plt.subplot(1,3,3)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"ground truth\")\n",
    "            plt.imshow(np.transpose(vutils.make_grid(y_test, nrow=1, padding=5, \n",
    "            normalize=True).cpu(), (1,2,0)))\n",
    "      \n",
    "            plt.savefig(os.path.join('log_path/','gan'+\"-\"+str(ep) +\".png\"))\n",
    "            plt.close()\n",
    "            img_list.append(figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t= Gen(x_test.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Gen,'Generative.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "# 'model_state_dict': Gen.state_dict(),\n",
    "# 'optimizer_state_dict': Gen_optim.state_dict(),\n",
    "# }, 'Gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for steps , (x,y) in enumerate(training_loader):\n",
    "#     Disc.zero_grad()\n",
    "#     r_p = torch.ones(5,1,30,30).cuda(0)\n",
    "#     r_f = torch.zeros(5,1,30,30).cuda(0)\n",
    "#     r_pc= Disc(y.cuda(0),x.cuda(0))\n",
    "#     loss_d = BCE(r_pc,r_p)\n",
    "    \n",
    "    \n",
    "#     fake = Gen(x.cuda(0))\n",
    "#     f_g = Disc(fake,x.cuda(0))\n",
    "#     lossf = BCE(f_g,r_f)\n",
    "#     Disc_loss = lossf + loss_d\n",
    "#     Disc_loss.backward()\n",
    "#     Disc_optim.step()\n",
    "    \n",
    "#     Gen.zero_grad()\n",
    "#     Disc(fake,x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_patch = Disc(fake,x)\n",
    "# f_gan_loss=BCE(f_patch,r_masks)\n",
    "\n",
    "# L1_loss = L1(fake,y)\n",
    "# Gen_loss = f_gan_loss + L1_lambda*L1_loss\n",
    "# Gen_loss.backward()\n",
    "\n",
    "# Gen_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disc_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
